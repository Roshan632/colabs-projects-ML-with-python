# -*- coding: utf-8 -*-
"""Day_7.5.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ao6tKSRH2zx4bv1XfHxmgHByNp1yK4lJ
"""

import torch
from torch import nn
import matplotlib.pyplot as plt

print (torch.__version__)

if torch.cuda.is_available():
    device= 'cuda'
elif torch.backends.mps.is_available():
    device=torch.device("mps")
else:
  device="cpu"
print(f"device is {device}")

# Create a dataset

m=0.7
c=0.3
X=torch.arange(0,1,0.02).unsqueeze(dim=1)
y=m*X+c
print("Shape of X :",X.shape)
print("Shape of y :",y.shape)

from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42)
print(X_train.shape,y_train.shape)
print(X_test.shape,y_test.shape)

def plot_predictions(train_data=X_train,
                     train_labels=y_train,
                     test_data=X_test,
                     test_labels=y_test,
                     predictions=None):
  plt.figure(figsize=(10,7))
  plt.scatter(train_data,train_labels,c="b",s=4,label="Training data")
  plt.scatter(test_data,test_labels,c="g",s=4,label="Testing data")
  plt.xlabel("X")
  plt.ylabel("y")
  plt.legend()
  if predictions is not None:
    plt.scatter(test_data,predictions,c="r",s=4,label="Predictions")

# Create a Neural Network class

class FirstNeuralNetwork(nn.Module):
  def __init__(self):
    super().__init__()
    self.weights = nn.Parameter(torch.randn(1, requires_grad=True, dtype=torch.float))
    self.bias = nn.Parameter(torch.randn(1, requires_grad=True, dtype=torch.float))

  def forward(self, x: torch.Tensor) -> torch.Tensor:
    return self.weights * x + self.bias

torch.manual_seed(42)
model= FirstNeuralNetwork()
list(model.parameters())

with torch.inference_mode():
  y_preds=model(X_test)
plot_predictions(predictions=y_preds)

# set up loss function and optimizer

loss_fn=nn.MSELoss()
optimizer= torch.optim.SGD(
    params=model.parameters(),
    lr=0.01
)

model.to(device)

# setup a training loop
epochs=500
X_train=X_train.to(device)
y_train=y_train.to(device)
X_test=X_test.to(device)
y_test=y_test.to(device)

trainLossList=[]
testLossList=[]

for epoch in range(epochs):

  model.train()  # training model
  train_preds=model(X_train)

#Compute train loss

  train_loss=loss_fn(train_preds,y_train)
  trainLossList.append(train_loss)
  #Zero grad Optimizer

  optimizer.zero_grad()

  # Backpropagate
  train_loss.backward()
  optimizer.step()


  with torch.inference_mode():

    test_preds=model(X_test)
    test_loss=loss_fn(test_preds,y_test)
  if(epoch%20==0):
    print(f"Epoch: {epoch} | Train Loss: {train_loss:.5f} | Test Loss: {test_loss:.5f}")
  trainLossList.append(train_loss.cpu().detach().numpy())
  testLossList.append(test_loss.cpu().detach().numpy())

